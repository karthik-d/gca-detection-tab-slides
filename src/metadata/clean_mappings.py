import pandas as pd
import csv
import os

from config import config

# File to Sample mapping
fs_mapping_path = os.path.join(config.get("METADATA_PATH"), 'mapping_file-sample.csv')

# Sample to Class mapping
sc_mapping_path = os.path.join(config.get("METADATA_PATH"), 'mapping_sample-class.csv')

# File-Sample-Class mapping
sc_mapping_cleaned_path = os.path.join(config.get("METADATA_PATH"), 'mapping_file-sample-class_cleaned.csv')

# NOT-Relevant-For-Analysis rows
no_analysis_path = os.path.join((config.get("METADATA_PATH")), 'not_analysis_relevant.csv')


def clean_mappings_sc():
	""" 
	clean out Sample-Class mapping (generated by pathologists)
	- reformat into relational design
	- eliminate/merge irrelevant columns
	- other minor steps
	"""

	fs_mapping = pd.read_csv(fs_mapping_path)
	sc_mapping = csv.reader(open(sc_mapping_path))
	header_row = next(sc_mapping)     # ignore row

	cleaned_mapping = pd.DataFrame(columns=[
		'slidename'
		'is_analysis_relevant',
		'is_positive',
		'notes'
	])

	sample = None
	notes = ''
	first_read = True
	for row in sc_mapping:

			sample = row[0]

			# discern sample-row and roi-row
			cnt_instances = len(fs_mapping.loc[fs_mapping['Sample']==sample, :])	
			is_valid_sample = ( cnt_instances>0 )

			if cnt_instances>1:
				print("[DUPLICATE] Found {} instances of {}".format(cnt_instances, sample))

			if is_valid_sample:

				if not first_read:  

					# handle duplicated in file accumulation      
					if(cnt_instances>1):
						# Take the first matching row
						fs_rows = fs_mapping.loc[fs_mapping['Sample']==sample_prestore, ['Slide Name', 'Order', 'Sample']].iloc[:1].to_dict(orient='records')[0]
					else:
						# print(f"Storing sample: {sample}...")
						# print("\n--------------------------------------------------")
						fs_rows = fs_mapping.loc[fs_mapping['Sample']==sample_prestore, ['Slide Name', 'Order', 'Sample']].to_dict(orient='records')[0]

					print("Saving", str(fs_rows['Slide Name']), "...")
					# Merge and Store collected rows    
					if analysis_row:               
						# Create row in merged_df
						num_rois = len(merged_rows['roi_number'])
						merged_rows['slidename'] = [ str(fs_rows['Slide Name']) for x in range(num_rois) ]
						merged_rows['order'] = [ str(fs_rows['Order']) for x in range(num_rois) ]
						merged_rows['sample'] = [ str(fs_rows['Sample']) for x in range(num_rois) ]
						merged_mapping = pd.concat([merged_mapping, pd.DataFrame(merged_rows)])
					else:
						merged_rows['slidename'] = [ str(fs_rows['Slide Name']) ]
						merged_rows['order'] = [ str(fs_rows['Order']) ]
						merged_rows['sample'] = [ str(fs_rows['Sample']) ]
						no_analysis = pd.concat([no_analysis, pd.DataFrame(merged_rows)])

				sample_prestore, is_analysis_relevant, _, notes = tuple(row) 
				# Reset dictionary for the new sample
				if is_analysis_relevant == 'N':
					# Eg: ['2020-041-11', 'N', '', 'Immuno']
					analysis_row = False
					merged_rows = {
						'slidename': [],
						'order': [],
						'sample': [],
						'notes': [notes]
					}
				else:
					analysis_row = True
					merged_rows = {
						'slidename': [],
						'order': [],
						'sample': [],
						'roi_number': [],
						'is_analysis_relevant': [],
						'is_positive': [],
						'notes': []
					}

			else:
				roi_num, is_analysis_relevant, is_positive, notes = tuple(row)
				merged_rows['roi_number'].append(roi_num)
				merged_rows['is_analysis_relevant'].append(is_analysis_relevant)
				merged_rows['is_positive'].append(is_positive)
				merged_rows['notes'].append(notes)
			
			first_read = False
		
	# Store last row
	fs_rows = fs_mapping.loc[fs_mapping['Sample']==sample_prestore, ['Slide Name', 'Order', 'Sample']].to_dict(orient='records')[0]
	num_rois = len(merged_rows['roi_number'])
	merged_rows['slidename'] = [ str(fs_rows['Slide Name']) for x in range(num_rois) ]
	merged_rows['order'] = [ str(fs_rows['Order']) for x in range(num_rois) ]
	merged_rows['sample'] = [ str(fs_rows['Sample']) for x in range(num_rois) ]
	# Append to merged dataframe
	merged_mapping = pd.concat([merged_mapping, pd.DataFrame(merged_rows)])

	print(merged_mapping)
	merged_mapping.to_csv(merged_mapping_path)

	print(no_analysis_path)
	no_analysis.to_csv(no_analysis_path)