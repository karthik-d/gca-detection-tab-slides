import pandas as pd
import csv
import os

from config import config

# File to Sample mapping
fs_mapping_path = os.path.join(config.get("METADATA_PATH"), 'mapping_file-sample.csv')

# Sample to Class mapping
sc_mapping_path = os.path.join(config.get("METADATA_PATH"), 'mapping_sample-class.csv')

# FSample to Class cleaned mapping
sc_mapping_cleaned_path = os.path.join(config.get("METADATA_PATH"), 'mapping_sample-class_cleaned.csv')

# File-Sample-Class mapping
merged_mapping_path = os.path.join(config.get("METADATA_PATH"), 'mapping_file-sample-class.csv')

# NOT-Relevant-For-Analysis rows
no_analysis_slidenames_path = os.path.join((config.get("METADATA_PATH")), 'not_analysis_relevant.csv')

# Relevant-For-Analysis rows
analysis_slidenames_path = os.path.join((config.get("METADATA_PATH")), 'analysis_relevant.csv')


def merge_mappings_fsc(save_cleaned_sc=True):
	""" 
	merge mappings across three levels: file-sample-class
	"""

	"""
	[ADDENDUM]: set save_cleaned_sc=True
	clean out Sample-Class mapping (generated by pathologists)
	- reformat into relational design
	- eliminate/merge irrelevant columns
	- other minor steps
	"""

	fs_mapping = pd.read_csv(fs_mapping_path)

	sc_mapping = csv.reader(open(sc_mapping_path))
	header_row = next(sc_mapping)     # ignore row

	merged_mapping = pd.DataFrame(columns=[
		'slidename',
		'order',
		'sample',
		'roi_number',
		'is_analysis_relevant',
		'is_positive',
		'notes'
	])

	no_analysis_slidenames = pd.DataFrame(columns=[
		'slidename',
		'order',
		'sample'
	])

	analysis_slidenames = pd.DataFrame(columns=[
		'slidename'
	])

	if save_cleaned_sc:
		cleaned_sc_mapping = pd.DataFrame(columns=[
			'slidename'
			'is_analysis_relevant',
			'is_positive',
			'notes'
		])

	sample = None
	notes = ''
	first_read = True
	duplicates = {}
	duplicates_analysis_relevant = {}
	for row in sc_mapping:

		sample = row[0]

		# discern sample-row and roi-row
		cnt_instances = len(fs_mapping.loc[fs_mapping['Sample']==sample, :])	
		is_valid_sample = ( cnt_instances>0 )			

		if is_valid_sample:

			if not first_read:  

				# handle duplicates in file accumulation      
				if(cnt_instances>1):
					# Take the first matching row
					fs_rows = fs_mapping.loc[fs_mapping['Sample']==sample_prestore, ['Slide Name', 'Order', 'Sample']].iloc[:1].to_dict(orient='records')[0]
				else:
					# print(f"Storing sample: {sample}...")
					# print("\n--------------------------------------------------")
					fs_rows = fs_mapping.loc[fs_mapping['Sample']==sample_prestore, ['Slide Name', 'Order', 'Sample']].to_dict(orient='records')[0]

				print("Saving", str(fs_rows['Slide Name']), "...")
				# Merge and Store collected rows    
				if analysis_row:               
					# Create row in merged_df
					num_rois = len(merged_rows['roi_number'])
					merged_rows['slidename'] = [ str(fs_rows['Slide Name']) for x in range(num_rois) ]
					merged_rows['order'] = [ str(fs_rows['Order']) for x in range(num_rois) ]
					merged_rows['sample'] = [ str(fs_rows['Sample']) for x in range(num_rois) ]
					# write to merged-mappings
					merged_mapping = pd.concat([merged_mapping, pd.DataFrame(merged_rows)])
					# write to analysis-relevant
					analysis_slidenames = pd.concat([analysis_slidenames, pd.DataFrame({'slidename': [sample_prestore]})])

				else:
					merged_rows['slidename'] = [ str(fs_rows['Slide Name']) ]
					merged_rows['order'] = [ str(fs_rows['Order']) ]
					merged_rows['sample'] = [ str(fs_rows['Sample']) ]
					# write to not-analysis-relevant
					no_analysis_slidenames = pd.concat([no_analysis_slidenames, pd.DataFrame(merged_rows)])

				# conditionally, write to cleaned-sc-mapping (both analysis relevant and otherwise)
				if save_cleaned_sc:
					cleaned_sc_mapping = pd.concat([
						cleaned_sc_mapping, 
						pd.DataFrame({
							'slidename': [str(fs_rows['Slide Name'])],
							'is_analysis_relevant': [is_analysis_relevant],
							'is_positive': [is_positive],
							'notes': [notes]
						})
					])

			sample_prestore, is_analysis_relevant, is_positive, notes = tuple(row) 
			
			# Reset trackers for the new sample				
			if is_analysis_relevant == 'N':
				# Eg: ['2020-037-9', 'N', '', 'Immuno']
				analysis_row = False
				merged_rows = {
					'slidename': [],
					'order': [],
					'sample': [],
					'notes': [notes]
				}

				# also write to cleaned-sc, since this will not trigger backward writing
				if save_cleaned_sc:
					cleaned_sc_mapping = pd.concat([
						cleaned_sc_mapping, 
						pd.DataFrame({
							'slidename': [sample_prestore],
							'is_analysis_relevant': [is_analysis_relevant],
							'is_positive': [is_positive],
							'notes': [notes]
						})
					])

				if cnt_instances>1:
					duplicates[sample] = cnt_instances	
			
			else:
				analysis_row = True
				merged_rows = {
					'slidename': [],
					'order': [],
					'sample': [],
					'roi_number': [],
					'is_analysis_relevant': [],
					'is_positive': [],
					'notes': []
				}

				if cnt_instances>1:
					duplicates[sample] = cnt_instances
					duplicates_analysis_relevant[sample] = cnt_instances	

		else:
			roi_num, is_analysis_relevant, is_positive, notes = tuple(row)
			merged_rows['roi_number'].append(roi_num)
			merged_rows['is_analysis_relevant'].append(is_analysis_relevant)
			merged_rows['is_positive'].append(is_positive)
			merged_rows['notes'].append(notes)
		
		first_read = False
		

	# Store last row
	fs_rows = fs_mapping.loc[fs_mapping['Sample']==sample_prestore, ['Slide Name', 'Order', 'Sample']].to_dict(orient='records')[0]
	num_rois = len(merged_rows['roi_number'])
	merged_rows['slidename'] = [ str(fs_rows['Slide Name']) for x in range(num_rois) ]
	merged_rows['order'] = [ str(fs_rows['Order']) for x in range(num_rois) ]
	merged_rows['sample'] = [ str(fs_rows['Sample']) for x in range(num_rois) ]
	# Append to merged dataframe
	merged_mapping = pd.concat([merged_mapping, pd.DataFrame(merged_rows)])
	# write to analysis-relevant
	analysis_slidenames = pd.concat([analysis_slidenames, pd.DataFrame({'slidename': [sample_prestore]})])

	print()
	print(merged_mapping_path)
	merged_mapping.to_csv(merged_mapping_path)

	print(analysis_slidenames_path)
	analysis_slidenames.to_csv(analysis_slidenames_path, index=False)

	print(no_analysis_slidenames_path)
	no_analysis_slidenames.to_csv(no_analysis_slidenames_path)

	if save_cleaned_sc:
		print(cleaned_sc_mapping)
		print(sc_mapping_cleaned_path)
		cleaned_sc_mapping.to_csv(sc_mapping_cleaned_path)

	print()
	for sample in duplicates_analysis_relevant:
		print("[DUPLICATE] Found {} instances of {}".format(duplicates_analysis_relevant[sample], sample))
	print()
	print("No. of samples with duplicates:", len(duplicates))
	print("No. of samples with duplicates - Relevant for Analysis:", len(duplicates_analysis_relevant))



